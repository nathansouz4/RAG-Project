{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-structured RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('app/src/shared/.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As normas brasileiras relacionadas a instalações elétricas abrangem uma variedade de aspectos, desde baixa tensão até instalações específicas em locais como áreas classificadas e sistemas fotovoltaicos. As principais normas da Associação Brasileira de Normas Técnicas (ABNT) sobre instalações elétricas incluem:\n",
    "\n",
    "* NBR 5410 - Instalações elétricas de baixa tensão: Trata das condições para o projeto, execução e manutenção de instalações elétricas de baixa tensão.\n",
    "\n",
    "* NBR 14039 - Instalações elétricas de média tensão de 1,0 kV a 36,2 kV: Estabelece as condições para projeto, execução e manutenção dessas instalações.\n",
    "\n",
    "* NBR 5413 - Iluminância de interiores: Define os requisitos para níveis de iluminância em ambientes internos.\n",
    "\n",
    "* NBR 13570 -  Instalações Elétricas em Locais de Afluência de Público - Requisitos específicos\n",
    "\n",
    "* ABNT NBR IEC 60079-14 - Instalações elétricas em atmosferas explosivas - Área classificada: Requisitos para instalações em áreas com risco de explosão.\n",
    "\n",
    "* NBR 10898 - Sistemas de iluminação de emergência: Especifica os requisitos para sistemas de iluminação de emergência em edifícios.\n",
    "\n",
    "* NBR 15514 - Recipientes transportáveis de gás liquefeito de petróleo (GLP) — Área de armazenamento — Requisitos de segurança\n",
    "    * Embora a norma NBR 15514 não seja diretamente uma norma de instalações elétricas, ela possui interseções com a área elétrica em aspectos relacionados à segurança, especialmente devido aos riscos potenciais de explosões e incêndios associados ao GLP.\n",
    "* NBR 5419 - Proteção contra descargas atmosféricas (em quatro partes):\n",
    "\n",
    "    * Parte 1: Princípios gerais\n",
    "    * Parte 2: Gerenciamento de risco\n",
    "    * Parte 3: Danos físicos a edificações e perigos à vida\n",
    "    * Parte 4: Sistemas elétricos e eletrônicos internos na estrutura\n",
    "\n",
    "    * NBR 16280 - Reforma em edificações - Sistema de gestão de reformas: Estabelece requisitos para reformas em edificações, incluindo instalações elétricas.\n",
    "\n",
    "\n",
    "Essas são algumas das principais normas que tratam de diversos aspectos das instalações elétricas no Brasil, garantindo segurança, eficiência e conformidade técnica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from typing import List\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "# Configure logging \n",
    "logging.basicConfig(filename='pdf_processing.log', level=logging.INFO, format='%(asctime)s %(message)s')\n",
    "\n",
    "def process_pdf_file(filename, path):\n",
    "    \"\"\"Processes a single PDF file and returns the extracted elements.\n",
    "\n",
    "    Logs information and errors during processing.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        raw_pdf_elements = partition_pdf(\n",
    "            filename=os.path.join(path, filename),  # Combine path and filename\n",
    "            extract_images_in_pdf=False,\n",
    "            infer_table_structure=True,\n",
    "            chunking_strategy=\"by_title\",\n",
    "            max_characters=4000,\n",
    "            new_after_n_chars=3800,\n",
    "            combine_text_under_n_chars=2000\n",
    "        )\n",
    "        logging.info(f\"Successfully processed PDF: {filename}\")\n",
    "        return raw_pdf_elements\n",
    "    except Exception as e:  # Catch specific PDF processing errors\n",
    "        logging.error(f\"Error processing PDF: {filename} - {e}\")\n",
    "        return []\n",
    "\n",
    "def process_single_pdf(pdf_folder_path: str, filename: str):\n",
    "    \"\"\"Helper function to process a single PDF file.\"\"\"\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        logging.info(f\"Reading PDF doc: {filename}\")\n",
    "        return process_pdf_file(filename, pdf_folder_path)\n",
    "    return []\n",
    "\n",
    "# Loop through PDF Files with ThreadPoolExecutor:\n",
    "def process_multiple_pdfs(pdf_folder_path: str, max_workers: int = 8) -> List:\n",
    "    \"\"\"Processes all PDF files within a specified folder using ThreadPoolExecutor.\n",
    "\n",
    "    Logs information and errors during processing.\n",
    "    \"\"\"\n",
    "    all_elements = []\n",
    "    filenames = [filename for filename in os.listdir(pdf_folder_path) if filename.endswith(\".pdf\")]\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        results = executor.map(lambda filename: process_single_pdf(pdf_folder_path, filename), filenames)\n",
    "\n",
    "    for result in results:\n",
    "        all_elements.extend(result)  # Extend the all_elements list\n",
    "\n",
    "    return all_elements\n",
    "\n",
    "# pdf_folder_path = \"/Users/nathan/workspace/tcc/app/src/database/pdf/\"\n",
    "# raw_pdfs_elements = process_multiple_pdfs(pdf_folder_path, max_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_folder_path = \"/Users/nathan/workspace/tcc/test\"\n",
    "raw_pdfs_elements = process_multiple_pdfs(pdf_folder_path, max_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store counts of each type\n",
    "category_counts = {}\n",
    "\n",
    "for element in raw_pdfs_elements:\n",
    "    category = str(type(element))\n",
    "    if category in category_counts:\n",
    "        category_counts[category] += 1\n",
    "    else:\n",
    "        category_counts[category] = 1\n",
    "\n",
    "# Unique_categories will have unique elements\n",
    "unique_categories = set(category_counts.keys())\n",
    "category_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# Define the Element class based on potential types returned by partition_pdf\n",
    "class Element(BaseModel):\n",
    "    type: str  # Textual representation of the element type (e.g., \"table\", \"text\")\n",
    "    text: Any  # Content of the element, can be text, tables, or other data structures\n",
    "\n",
    "# Categorize by type\n",
    "def categorize_elements(raw_pdf_elements) -> list[Element]:\n",
    "    \"\"\"Categorizes elements by type and returns a dictionary with counts.\"\"\"\n",
    "    categorized_elements = [] # Initialize category counts\n",
    "    for element in raw_pdf_elements:\n",
    "        if \"unstructured.documents.elements.Table\" in str(type(element)):\n",
    "            categorized_elements.append(Element(type=\"table\", text=str(element)))\n",
    "        elif \"unstructured.documents.elements.CompositeElement\" in str(type(element)):\n",
    "            categorized_elements.append(Element(type=\"text\", text=str(element)))\n",
    "    return categorized_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved categorization function with clear structure\n",
    "all_categories = categorize_elements(raw_pdfs_elements)\n",
    "print(len(all_categories))\n",
    "\n",
    "# Tables\n",
    "table_elements = [e for e in all_categories if e.type == \"table\"]\n",
    "print(f\"Number of tables: {len(table_elements)}\")\n",
    "\n",
    "# Text\n",
    "text_elements = [e for e in all_categories if e.type == \"text\"]\n",
    "print(f\"Number of text elements: {len(text_elements)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the number of tokens for each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the text elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def cleaning_text(text_element: str)-> str:\n",
    "    \n",
    "    # Remover quebras de linha desnecessárias\n",
    "    text = re.sub(r'\\n+', ' ', text_element)\n",
    "    \n",
    "    # Remover números de página e sequências de dígitos isolados\n",
    "    text = re.sub(r'\\s\\d+\\s', ' ', text)\n",
    "    \n",
    "    # Remover espaços extras\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # Corrigir espaços antes de pontuação\n",
    "    text = re.sub(r'\\s+([,.;:])', r'\\1', text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to texts\n",
    "texts = [i.text for i in text_elements]\n",
    "\n",
    "cleaned_texts = [cleaning_text(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibir os textos limpos\n",
    "for cleaned_text in cleaned_texts:\n",
    "    print(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing tables and text chunks from pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "\n",
    "model = GoogleGenerativeAI(model=\"gemini-pro\",\n",
    "                 temperature=0.3, top_p=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Prompt\n",
    "prompt_text = \"\"\"Você é um assistente com a tarefa de resumir tabelas e textos de normas brasileiras sobre instalações elétricas.\n",
    "Faça um resumo sucinto da tabela ou do texto a seguir. Tabela ou texto: {element} \"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(prompt_text)\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "summarize_chain = {\"element\": lambda x: x} | prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to tables\n",
    "tables = [i.text for i in table_elements]\n",
    "table_summaries = summarize_chain.batch(tables, {\"max_concurrency\": 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to texts\n",
    "# texts = [i.text for i in text_elements]\n",
    "text_summaries = summarize_chain.batch(cleaned_texts, {\"max_concurrency\": 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(texts))\n",
    "print(len(cleaned_texts))\n",
    "print(len(text_summaries))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analisar os crunks pai com filho(summarized by gemini model)\n",
    "import pandas as pd\n",
    "\n",
    "text_data = {\"Texts\": texts, \n",
    "             \"Cleaned Texts\": cleaned_texts,\n",
    "             \"Text_summaries\": text_summaries}\n",
    "\n",
    "df = pd.DataFrame(text_data)\n",
    "\n",
    "df.head()\n",
    "\n",
    "# # Configurar a largura máxima da coluna\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# # Exibir as 5 primeiras linhas do DataFrame\n",
    "# print(df.head(9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text_summaries'].iloc[12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add to vectorstore\n",
    "Use Multi Vector Retriever with summaries:\n",
    "\n",
    "- InMemoryStore stores the raw text, tables\n",
    "- vectorstore stores the embedded summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "gemini_embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", task_type=\"retrieval_document\")\n",
    "gemini_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Conexão ao banco de dados SQLite\n",
    "conn = sqlite3.connect('chroma_db/test_summaries/chroma.sqlite3')\n",
    "\n",
    "\n",
    "# Executa a consulta e retorna um DataFrame\n",
    "df = pd.read_sql_query(\"SELECT * FROM collections\", conn)\n",
    "\n",
    "# Exibe o DataFrame\n",
    "print(df,\"\\n\\n\")\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the empty vector DB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "persist_directory = \"./chroma_db/test_summaries\"\n",
    "\n",
    "# inicianlizing the vectorstore\n",
    "vectorstore = Chroma(collection_name=\"summaries_nr1010\", \n",
    "                        embedding_function=gemini_embeddings,\n",
    "                        persist_directory=persist_directory)\n",
    "\n",
    "# Conexão ao banco de dados SQLite\n",
    "conn = sqlite3.connect('chroma_db/test_summaries/chroma.sqlite3')\n",
    "\n",
    "tables = pd.read_sql_query(\"SELECT name FROM sqlite_master WHERE type='table'\", conn)\n",
    "print(tables, \"\\n\")\n",
    "\n",
    "# Executa a consulta e retorna um DataFrame\n",
    "df = pd.read_sql_query(\"SELECT * FROM embedding_fulltext_search\", conn)\n",
    "\n",
    "# Exibe o DataFrame\n",
    "print(df,\"\\n\\n\")\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conexão ao banco de dados SQLite\n",
    "conn = sqlite3.connect('chroma_db/test_summaries/chroma.sqlite3')\n",
    "\n",
    "# Executa a consulta e retorna um DataFrame\n",
    "df = pd.read_sql_query(\"SELECT * FROM collections\", conn)\n",
    "\n",
    "# Exibe o DataFrame\n",
    "print(df,\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi Vector Retriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "\n",
    "# The storage layer for the parent documents\n",
    "store = InMemoryStore()\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "# The retriever (empty to start)\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    id_key=id_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add the documents to the vectorial database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Apply to tables\n",
    "tables = [i.text for i in table_elements]\n",
    "# Apply to texts\n",
    "# texts = [i.text for i in text_elements]\n",
    "\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "# Add texts\n",
    "doc_ids = [str(uuid.uuid4()) for _ in texts]\n",
    "page_content_texts = [\n",
    "    Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
    "    for i, s in enumerate(text_summaries)\n",
    "]\n",
    "\n",
    "vectorstore.add_documents(page_content_texts)\n",
    "retriever.docstore.mset(list(zip(doc_ids, cleaned_texts)))\n",
    "\n",
    "# Add tables\n",
    "table_ids = [str(uuid.uuid4()) for _ in tables]\n",
    "page_content_tables = [\n",
    "    Document(page_content=s, metadata={id_key: table_ids[i]})\n",
    "    for i, s in enumerate(table_summaries)\n",
    "]\n",
    "\n",
    "vectorstore.add_documents(page_content_tables)\n",
    "# retriever.docstore.mset(list(zip(table_ids, tables)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Conexão ao banco de dados SQLite\n",
    "conn = sqlite3.connect('chroma_db/test_summaries/chroma.sqlite3')\n",
    "\n",
    "# Executa a consulta e retorna um DataFrame\n",
    "df = pd.read_sql_query(\"SELECT * FROM embedding_fulltext_search\", conn)\n",
    "\n",
    "# Exibe o DataFrame\n",
    "print(df,\"\\n\\n\")\n",
    "print(f\"Colunas: {df.columns} \\n\")\n",
    "\n",
    "# print(df['string_value'].iloc[1])\n",
    "\n",
    "# Fecha a conexão\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of the vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Conexão ao banco de dados SQLite\n",
    "conn = sqlite3.connect('chroma_db/chroma.sqlite3')\n",
    "\n",
    "tables = pd.read_sql_query(\"SELECT name FROM sqlite_master WHERE type='table'\", conn)\n",
    "\n",
    "print(tables)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Conexão ao banco de dados SQLite\n",
    "conn = sqlite3.connect('chroma_db/chroma.sqlite3')\n",
    "\n",
    "# Consulta SQL\n",
    "query = \"SELECT * FROM embedding_fulltext_search\"\n",
    "\n",
    "# Executa a consulta e retorna um DataFrame\n",
    "df = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Exibe o DataFrame\n",
    "print(df,\"\\n\\n\")\n",
    "print(f\"Colunas: {df.columns}\")\n",
    "print(df['string_value'].iloc[1])\n",
    "\n",
    "# Fecha a conexão\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vector store-backed retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from disk\n",
    "# vectorstore_db = Chroma(\n",
    "#                         persist_directory=\"./chroma_db\",       # Directory of db\n",
    "#                         embedding_function=gemini_embeddings   # Embedding model\n",
    "#                    )\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 1})\n",
    "\n",
    "# retriever = vectorstore.as_retriever(\n",
    "#     search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.7}\n",
    "# )\n",
    "\n",
    "# retriever = vectorstore.as_retriever(search_type=\"mmr\")\n",
    "\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"O que diz o topico 10.2.8.1 da norma regulamentadora NR 10?\"\n",
    "docs = retriever.invoke(query)\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parent Document Retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multivector Retriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "persist_directory = \"./chroma_db\"\n",
    "\n",
    "# Load from disk\n",
    "vectorstore = Chroma(collection_name=\"summaries\", \n",
    "                        embedding_function=gemini_embeddings,\n",
    "                        persist_directory=persist_directory)\n",
    "\n",
    "# The storage layer for the parent documents\n",
    "store = InMemoryStore()\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "# The retriever (empty to start)\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    id_key=id_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "from IPython.display import Markdown\n",
    "\n",
    "# def to_markdown(text):\n",
    "#   text = text.replace('•', '  *')\n",
    "#   return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
    "\n",
    "def to_markdown(text):\n",
    "    text = text.replace('•', '*')\n",
    "    text = textwrap.dedent(text).strip()\n",
    "\n",
    "    return Markdown(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With chat memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain.chains.history_aware_retriever import create_history_aware_retriever\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableMap\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "\n",
    "model = GoogleGenerativeAI(model=\"gemini-pro\", temperature=0.3, top_p=0.85)\n",
    "\n",
    "\n",
    "### Contextualize question ###\n",
    "contextualize_system_prompt = \"\"\"Dado um histórico de bate-papo e a última pergunta do usuário \\\n",
    "que pode fazer referência ao contexto no histórico de bate-papo, formule uma pergunta autônoma \\\n",
    "que possa ser compreendida sem o histórico do bate-papo. NÃO responda à pergunta, \\\n",
    "apenas reformule-a se necessário e, caso contrário, devolva-a como está.\"\"\"\n",
    "\n",
    "\n",
    "contextualize_system_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"ai\", contextualize_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "history_aware_retriever = create_history_aware_retriever(model, \n",
    "                                                         retriever, \n",
    "                                                         contextualize_system_prompt)\n",
    "\n",
    "\n",
    "### Answer question ###\n",
    "template = \"\"\"Você é um assistente chamado Spark e sua função é responder dúvidas e questionamentos relacionadas as instalações elétricas brasileiras \\\n",
    "com base no contexto, o qual pode incluir textos e/ou tabelas referentes as normas brasileiras (NBRs): \\\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([(\"ai\", template),\n",
    "                                           MessagesPlaceholder(\"chat_history\"),\n",
    "                                           (\"human\", \"{input}\")])\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(model, prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n",
    "\n",
    "### Statefully manage chat history ###\n",
    "store = {}\n",
    "session_id = \"default_session_id\"\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    ")\n",
    "\n",
    "conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_markdown(conversational_rag_chain.invoke(\n",
    "    {\"input\": \"O que diz a norma NR 10?\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": \"abc123\"}\n",
    "    },  \n",
    ")[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_markdown(conversational_rag_chain.invoke(\n",
    "    {\"input\": \"Qual foi minha pergunta anterior?\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": \"abc123\"}\n",
    "    },  \n",
    ")[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_markdown(conversational_rag_chain.invoke(\n",
    "    {\"input\": \"Qual objetivo da norma regulamentadora NR 10?\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": session_id}\n",
    "    },  \n",
    ")[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_markdown(conversational_rag_chain.invoke(\n",
    "    {\"input\": \"qual foi minha pergunta anterior?\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": session_id}\n",
    "    },  \n",
    ")[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"O que diz o topico 10.2.8.1 da norma regulamentadora NR 10?\" \n",
    "\n",
    "to_markdown(conversational_rag_chain.invoke(\n",
    "    {\"input\":query},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": session_id}\n",
    "    },  \n",
    ")[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Como assim voce n tem acesso ao conteudo da NR 10?\" \n",
    "\n",
    "to_markdown(conversational_rag_chain.invoke(\n",
    "    {\"input\":query},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": session_id}\n",
    "    },  \n",
    ")[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Me diga o que a NR 10 fala sobre EPIS (equipamentos de proteção individual).\" \n",
    "\n",
    "to_markdown(conversational_rag_chain.invoke(\n",
    "    {\"input\":query},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": session_id}\n",
    "    },  \n",
    ")[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without chat memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableMap\n",
    "\n",
    "\n",
    "model = GoogleGenerativeAI(model=\"gemini-pro\", temperature=0.3, top_p=0.85)\n",
    "\n",
    "# Prompt template\n",
    "template = \"\"\"Você é um assistente chamado Spark e sua função é responder dúvidas e questionamentos relacionadas as instalações elétricas brasileiras com base no contexto, o qual pode incluir textos e/ou tabelas referentes as normas brasileiras (NBRs):\n",
    "{context}\n",
    "Question: {question}\n",
    "\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Função para imprimir o contexto\n",
    "def print_context(context):\n",
    "    print(\"Contexto fornecido:\", context)\n",
    "    return context\n",
    "\n",
    "# RAG pipeline com etapa intermediária para capturar e imprimir o contexto\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | RunnableMap({\"context\": print_context, \"question\": RunnablePassthrough()})\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"O que diz o tópico 10.2.9.1 da Norma NR 10?\"\n",
    "to_markdown(chain.invoke(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Qual seu nome?\"\n",
    "to_markdown(chain.invoke(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Quais são os requisitos de qualificação profissional para os trabalhadores que atuam em atividades abrangidas pela NR 10?\"\n",
    "to_markdown(chain.invoke(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Quais são as responsabilidades dos empregadores e dos trabalhadores em relação à NR 10?\"\n",
    "to_markdown(chain.invoke(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Que tipos de Equipamentos de Proteção Individual (EPIs) são exigidos pela NR 10 para os trabalhadores que atuam com eletricidade?\"\n",
    "to_markdown(chain.invoke(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Quais são as exigências da NR 10 para as instalações elétricas em áreas classificadas?\"\n",
    "to_markdown(chain.invoke(query))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
